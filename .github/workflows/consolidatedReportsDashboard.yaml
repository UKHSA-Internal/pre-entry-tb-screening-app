name: Nightly Tests Dashboard

on:
  workflow_run:
    workflows: ["Nightly Cypress Tests - DEV", "Nightly Cypress Tests - QAT", "Nightly Cypress Tests - PREPROD"]
    types: [completed]
  workflow_dispatch: # Allow manual triggering

permissions:
  contents: read
  pages: write
  id-token: write

jobs:
  wait-for-all-workflows:
    name: Wait for all environment workflows to complete
    runs-on: ubuntu-latest
    steps:
      - name: Wait for all workflows to complete
        id: check-completion
        uses: actions/github-script@v7
        with:
          script: |
            const { owner, repo } = context.repo;
            const workflows = ['Nightly Cypress Tests - DEV', 'Nightly Cypress Tests - QAT', 'Nightly Cypress Tests - PREPROD'];
            
            // Wait up to 30 minutes for all workflows to complete
            let attempts = 0;
            const maxAttempts = 60; // 30 minutes with 30-second intervals
            
            while (attempts < maxAttempts) {
              console.log(`Attempt ${attempts + 1}/${maxAttempts}: Checking workflow completion status...`);
              
              let allComplete = true;
              const results = {};
              
              for (const workflowName of workflows) {
                // Get the latest run for each workflow
                const { data: runs } = await github.rest.actions.listWorkflowRunsForRepo({
                  owner,
                  repo,
                  event: 'schedule', // Only scheduled runs
                  status: 'completed',
                  per_page: 1
                });
                
                const latestRun = runs.workflow_runs.find(run => 
                  run.name === workflowName && 
                  run.created_at >= new Date(Date.now() - 24 * 60 * 60 * 1000).toISOString() // Within last 24 hours
                );
                
                if (!latestRun) {
                  console.log(`${workflowName}: No recent completed run found`);
                  allComplete = false;
                } else {
                  console.log(`${workflowName}: ${latestRun.conclusion} (${latestRun.created_at})`);
                  results[workflowName] = latestRun.conclusion;
                }
              }
              
              if (allComplete) {
                console.log('All workflows completed!');
                return;
              }
              
              attempts++;
              if (attempts < maxAttempts) {
                console.log('Waiting 30 seconds before next check...');
                await new Promise(resolve => setTimeout(resolve, 30000));
              }
            }
            
            console.log('Timeout reached. Proceeding with available results.');

  generate-dashboard:
    name: Generate Consolidated Dashboard
    needs: wait-for-all-workflows
    if: always()
    runs-on: ubuntu-latest
    
    environment:
      name: github-pages
      url: ${{ steps.deployment.outputs.page_url }}

    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Download artifacts using GitHub API
        continue-on-error: true
        uses: actions/github-script@v7
        with:
          script: |
            const fs = require('fs');
            const path = require('path');
            
            // Create artifacts directory
            const artifactsDir = './artifacts';
            if (!fs.existsSync(artifactsDir)) {
              fs.mkdirSync(artifactsDir, { recursive: true });
            }
            
            // Workflow names and their corresponding environment prefixes
            const workflowMappings = {
              'nightlyCypressTests-DEV.yaml': 'dev',
              'nightlyCypressTests-QAT.yaml': 'qat', 
              'nightlyCypressTests-Preprod.yaml': 'preprod'
            };
            
            const environments = ['dev', 'qat', 'preprod'];
            const browsers = ['chrome', 'edge'];
            
            // Function to download and extract artifact
            async function downloadArtifact(artifactId, downloadPath) {
              try {
                const download = await github.rest.actions.downloadArtifact({
                  owner: context.repo.owner,
                  repo: context.repo.repo,
                  artifact_id: artifactId,
                  archive_format: 'zip'
                });
                
                // Write the zip file
                const zipPath = `${downloadPath}.zip`;
                fs.writeFileSync(zipPath, Buffer.from(download.data));
                
                // Extract zip using Node.js (basic extraction)
                const AdmZip = require('adm-zip');
                const zip = new AdmZip(zipPath);
                zip.extractAllTo(downloadPath, true);
                
                // Clean up zip file
                fs.unlinkSync(zipPath);
                
                console.log(`Downloaded and extracted artifact to: ${downloadPath}`);
                return true;
              } catch (error) {
                console.error(`Failed to download artifact ${artifactId}:`, error.message);
                return false;
              }
            }
            
            // Get recent workflow runs for each environment
            for (const [workflowFile, env] of Object.entries(workflowMappings)) {
              console.log(`Processing ${env} environment (${workflowFile})...`);
              
              try {
                // Get recent workflow runs
                const { data: runs } = await github.rest.actions.listWorkflowRuns({
                  owner: context.repo.owner,
                  repo: context.repo.repo,
                  workflow_id: workflowFile,
                  status: 'completed',
                  per_page: 10
                });
                
                // Find the most recent run from the last 24 hours
                const yesterday = new Date(Date.now() - 24 * 60 * 60 * 1000);
                const recentRun = runs.workflow_runs.find(run => 
                  new Date(run.created_at) >= yesterday
                );
                
                if (!recentRun) {
                  console.log(`No recent workflow runs found for ${env}`);
                  continue;
                }
                
                console.log(`Found recent run for ${env}: ${recentRun.id} (${recentRun.conclusion})`);
                
                // Get artifacts for this run
                const { data: artifacts } = await github.rest.actions.listWorkflowRunArtifacts({
                  owner: context.repo.owner,
                  repo: context.repo.repo,
                  run_id: recentRun.id
                });
                
                // Create environment directory
                const envDir = path.join(artifactsDir, env);
                if (!fs.existsSync(envDir)) {
                  fs.mkdirSync(envDir, { recursive: true });
                }
                
                // Download artifacts matching our pattern
                for (const artifact of artifacts.artifacts) {
                  const artifactName = artifact.name;
                  
                  // Check if this artifact matches our expected patterns
                  for (const browser of browsers) {
                    if (artifactName.includes(`${env}-${browser}-results`)) {
                      console.log(`Downloading artifact: ${artifactName}`);
                      const downloadPath = path.join(envDir, artifactName);
                      await downloadArtifact(artifact.id, downloadPath);
                      break;
                    }
                  }
                }
                
              } catch (error) {
                console.error(`Error processing ${env} environment:`, error.message);
              }
            }
            
            // List what we've downloaded for debugging
            console.log('\nDownloaded artifacts structure:');
            function listDir(dir, prefix = '') {
              if (fs.existsSync(dir)) {
                const items = fs.readdirSync(dir);
                for (const item of items) {
                  const itemPath = path.join(dir, item);
                  const stat = fs.statSync(itemPath);
                  console.log(`${prefix}${item}${stat.isDirectory() ? '/' : ''}`);
                  if (stat.isDirectory()) {
                    listDir(itemPath, prefix + '  ');
                  }
                }
              }
            }
            listDir(artifactsDir);

      - name: Install required dependencies for artifact extraction
        run: |
          npm install adm-zip

      - name: Generate consolidated test results
        id: results
        run: |
          mkdir -p dashboard
          
          echo "Processing test results..."
          
          ENVIRONMENTS=("dev" "qat" "preprod")
          BROWSERS=("chrome" "edge")
          
          # Initialize counters
          TOTAL_COMBINATIONS=6
          FAILED_COMBINATIONS=0
          TOTAL_FAILED_TESTS=0
          
          # Create JSON structure
          echo "{" > dashboard/test-results.json
          echo "  \"environments\": {" >> dashboard/test-results.json
          
          FIRST_ENV=true
          for env in "${ENVIRONMENTS[@]}"; do
            if [ "$FIRST_ENV" = false ]; then
              echo "    }," >> dashboard/test-results.json
            fi
            FIRST_ENV=false
            
            echo "    \"$env\": {" >> dashboard/test-results.json
            
            FIRST_BROWSER=true
            for browser in "${BROWSERS[@]}"; do
              if [ "$FIRST_BROWSER" = false ]; then
                echo "      ," >> dashboard/test-results.json
              fi
              FIRST_BROWSER=false
              
              # Look for result file
              RESULT="NOT RUN"
              SCREENSHOT_COUNT=0
              
              if [ -f "artifacts/$env/$env-$browser-results/result.txt" ]; then
                RESULT=$(cat "artifacts/$env/$env-$browser-results/result.txt")
              fi
              
              if [ -f "artifacts/$env/$env-$browser-results/screenshot_count.txt" ]; then
                SCREENSHOT_COUNT=$(cat "artifacts/$env/$env-$browser-results/screenshot_count.txt")
              fi
              
              if [ "$RESULT" = "FAIL" ]; then
                ((FAILED_COMBINATIONS++))
                TOTAL_FAILED_TESTS=$((TOTAL_FAILED_TESTS + SCREENSHOT_COUNT))
              fi
              
              echo "      \"$browser\": \"$RESULT\"" >> dashboard/test-results.json
            done
          done
          
          echo "    }" >> dashboard/test-results.json
          echo "  }," >> dashboard/test-results.json
          
          # Calculate success rate
          SUCCESS_RATE=$(( (TOTAL_COMBINATIONS - FAILED_COMBINATIONS) * 100 / TOTAL_COMBINATIONS ))
          
          # Determine overall status
          if [ $FAILED_COMBINATIONS -eq 0 ]; then
            OVERALL_STATUS="PASS"
          else
            OVERALL_STATUS="FAIL"
          fi
          
          # Complete JSON
          cat >> dashboard/test-results.json << EOF
            "overallStatus": "$OVERALL_STATUS",
            "successRate": "${SUCCESS_RATE}%",
            "failedTests": $TOTAL_FAILED_TESTS,
            "failedCombinations": $FAILED_COMBINATIONS,
            "totalCombinations": $TOTAL_COMBINATIONS,
            "timestamp": "$(date -u +%Y-%m-%dT%H:%M:%S.%3NZ)",
            "runUrl": "${{ github.server_url }}/${{ github.repository }}/actions/runs/${{ github.run_id }}"
          }
          EOF
          
          # Set outputs
          echo "overall_status=$OVERALL_STATUS" >> $GITHUB_OUTPUT
          echo "success_rate=${SUCCESS_RATE}%" >> $GITHUB_OUTPUT
          echo "failed_tests=$TOTAL_FAILED_TESTS" >> $GITHUB_OUTPUT
          echo "failed_combinations=$FAILED_COMBINATIONS" >> $GITHUB_OUTPUT
          
          echo "Dashboard data generated successfully!"
          cat dashboard/test-results.json

      - name: Create dashboard HTML
        run: |
          cat > dashboard/index.html << 'EOF'
          <!DOCTYPE html>
          <html lang="en">
          <head>
              <meta charset="UTF-8">
              <meta name="viewport" content="width=device-width, initial-scale=1.0">
              <title>Pre-Entry TB Screening - Nightly Test Dashboard</title>
              <style>
                  body { font-family: Arial, sans-serif; margin: 0; padding: 20px; background: #f5f5f5; }
                  .container { max-width: 1200px; margin: 0 auto; background: white; padding: 20px; border-radius: 8px; box-shadow: 0 2px 10px rgba(0,0,0,0.1); }
                  .status-pass { color: #22c55e; }
                  .status-fail { color: #ef4444; }
                  .status-not-run { color: #f59e0b; }
                  table { border-collapse: collapse; width: 100%; margin: 20px 0; }
                  th, td { border: 1px solid #ddd; padding: 12px; text-align: center; }
                  th { background: #f8f9fa; font-weight: 600; }
                  .stats { display: grid; grid-template-columns: repeat(auto-fit, minmax(200px, 1fr)); gap: 20px; margin: 20px 0; }
                  .stat-card { background: #f8f9fa; padding: 15px; border-radius: 6px; text-align: center; }
                  .loading { text-align: center; padding: 40px; }
              </style>
          </head>
          <body>
              <div class="container">
                  <div class="loading">Loading dashboard...</div>
              </div>
              
              <script>
                  fetch('./test-results.json')
                      .then(response => response.json())
                      .then(data => {
                          const getStatusClass = (status) => {
                              switch(status) {
                                  case 'PASS': return 'status-pass';
                                  case 'FAIL': return 'status-fail';
                                  case 'NOT RUN': return 'status-not-run';
                                  default: return 'status-not-run';
                              }
                          };
                          
                          const getStatusIcon = (status) => {
                              switch(status) {
                                  case 'PASS': return '‚úÖ';
                                  case 'FAIL': return '‚ùå';
                                  case 'NOT RUN': return '‚ùì';
                                  default: return '‚ùì';
                              }
                          };
                          
                          let environmentTable = '<table><tr><th>Browser</th><th>DEV</th><th>QAT</th><th>PREPROD</th></tr>';
                          
                          ['chrome', 'edge'].forEach(browser => {
                              const capitalizedBrowser = browser.charAt(0).toUpperCase() + browser.slice(1);
                              environmentTable += `<tr>
                                  <td><strong>${capitalizedBrowser}</strong></td>
                                  <td class="${getStatusClass(data.environments.dev[browser])}">${getStatusIcon(data.environments.dev[browser])} ${data.environments.dev[browser]}</td>
                                  <td class="${getStatusClass(data.environments.qat[browser])}">${getStatusIcon(data.environments.qat[browser])} ${data.environments.qat[browser]}</td>
                                  <td class="${getStatusClass(data.environments.preprod[browser])}">${getStatusIcon(data.environments.preprod[browser])} ${data.environments.preprod[browser]}</td>
                              </tr>`;
                          });
                          environmentTable += '</table>';
                          
                          document.querySelector('.container').innerHTML = `
                              <h1>üåô Pre-Entry TB Screening - Nightly Tests Dashboard</h1>
                              <div class="stats">
                                  <div class="stat-card">
                                      <h3>Overall Status</h3>
                                      <p class="${getStatusClass(data.overallStatus)}">${getStatusIcon(data.overallStatus)} ${data.overallStatus}</p>
                                  </div>
                                  <div class="stat-card">
                                      <h3>Success Rate</h3>
                                      <p>${data.successRate}</p>
                                  </div>
                                  <div class="stat-card">
                                      <h3>Failed Tests</h3>
                                      <p>${data.failedTests}</p>
                                  </div>
                                  <div class="stat-card">
                                      <h3>Failed Combinations</h3>
                                      <p>${data.failedCombinations}/${data.totalCombinations}</p>
                                  </div>
                              </div>
                              
                              <h2>Test Results Matrix</h2>
                              ${environmentTable}
                              
                              <p><strong>Last Updated:</strong> ${new Date(data.timestamp).toLocaleString()}</p>
                              <p><a href="${data.runUrl}" target="_blank" style="background: #0066cc; color: white; padding: 8px 16px; text-decoration: none; border-radius: 4px;">üìä View Detailed Results</a></p>
                          `;
                      })
                      .catch(err => {
                          document.querySelector('.container').innerHTML = '<div style="color: red; text-align: center; padding: 40px;">Error loading test results: ' + err.message + '</div>';
                      });
              </script>
          </body>
          </html>
          EOF

      - name: Setup Pages
        uses: actions/configure-pages@v4

      - name: Upload to GitHub Pages
        uses: actions/upload-pages-artifact@v3
        with:
          path: "./dashboard"

      - name: Deploy to GitHub Pages
        id: deployment
        uses: actions/deploy-pages@v4

      - name: Generate summary
        run: |
          echo "# üåô Nightly Test Results Summary" >> $GITHUB_STEP_SUMMARY
          echo "**Dashboard URL:** ${{ steps.deployment.outputs.page_url }}" >> $GITHUB_STEP_SUMMARY
          echo "**Overall Status:** ${{ steps.results.outputs.overall_status }}" >> $GITHUB_STEP_SUMMARY
          echo "**Success Rate:** ${{ steps.results.outputs.success_rate }}" >> $GITHUB_STEP_SUMMARY
          echo "**Failed Tests:** ${{ steps.results.outputs.failed_tests }}" >> $GITHUB_STEP_SUMMARY
          echo "**Failed Combinations:** ${{ steps.results.outputs.failed_combinations }}/9" >> $GITHUB_STEP_SUMMARY
          
          if [[ "${{ steps.results.outputs.overall_status }}" == "PASS" ]]; then
            echo "::notice::All nightly tests passed across all environments! Dashboard: ${{ steps.deployment.outputs.page_url }}"
          else
            echo "::error::Some nightly tests failed. Check dashboard: ${{ steps.deployment.outputs.page_url }}"
            exit 1
          fi